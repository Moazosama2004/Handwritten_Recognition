{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc2501a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabnanny import check\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "from numpy import imag\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread,imshow\n",
    "from skimage.transform import resize\n",
    "import xlsxwriter\n",
    "import mss\n",
    "import mss.tools\n",
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "from operator import indexOf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f7580",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a74f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "        self.x = self.y = 0\n",
    "        \n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Draw the letter(A or J) for now you want to recognize with genetics algorithms \\n then press the take screen button to save the image \\n then close this window\", font=(\"Helvetica\", 20))\n",
    "        self.label1 = tk.Label(self, text=\"please first maximize this window before captureing the image:\", font=(\"Helvetica\", 30))\n",
    "        self.takeScreen_btn = tk.Button(self, text = \"takeScreen\", command = self.takeScreen)   \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=6, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=6, column=1,pady=2, padx=2)\n",
    "        self.takeScreen_btn.grid(row=8, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=8, column=0, pady=2)\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label1.grid(row=0, column=1,pady=2, padx=2)\n",
    "\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "        \n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        \n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "\n",
    "    def takeScreen(self):\n",
    "        with mss.mss() as sct:\n",
    "            monitor = {\"top\": 25, \"left\": 0, \"width\": 300, \"height\": 300}\n",
    "            output = \"checkImage.png\".format(**monitor)\n",
    "            sct_img = sct.grab(monitor)\n",
    "            mss.tools.to_png(sct_img.rgb, sct_img.size, output=output)\n",
    "            print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4057760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuction_to_capture_and_store_the_check_image():\n",
    "    app = App()\n",
    "    mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6afb4",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3657a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_extract_the_features_of_the_initial_population_for_J_dataset():\n",
    "    data = pd.read_excel(\"j.xlsx\")\n",
    "    print(\"-------------------------Column headings----------------------------------------\")\n",
    "    print(list(data))\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    images=data['image path']\n",
    "    list_of_images_graphs=[]\n",
    "    print(\"--------------------------extracting the verteces of each image in the dataset seperatly---------------------------------------\")\n",
    "    for i in range(54):\n",
    "        print(\"extracting the features grapph for image number:\", i,\" in the dataset\")\n",
    "        readed_image=imread(images[i])\n",
    "        features_matrix=np.zeros((readed_image.shape[0],readed_image.shape[1]))\n",
    "        for i in range(0,readed_image.shape[0]):\n",
    "            for j in range(0,readed_image.shape[1]):\n",
    "                features_matrix[i][j] = ((int(readed_image[i,j,0]) + int(readed_image[i,j,1]) + int(readed_image[i,j,2]))/3)\n",
    "        resized_image=resize(features_matrix,(30,30))\n",
    "\n",
    "        garaph_of_the_current_image=[]\n",
    "        for i in range(0,resized_image.shape[0]):\n",
    "            for j in range(0,resized_image.shape[1]):\n",
    "                if(resized_image[i][j]<=150):\n",
    "                    garaph_of_the_current_image.append((i,j))\n",
    "        list_of_images_graphs.append(garaph_of_the_current_image)    \n",
    "    return list_of_images_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "766b3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_extract_the_features_of_the_initial_population_For_a_dataset():\n",
    "    data = pd.read_excel(\"a.xlsx\")\n",
    "    print(\"-------------------------Column headings----------------------------------------\")\n",
    "    print(list(data))\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    images=data['image path']\n",
    "    list_of_images_graphs=[]\n",
    "    print(\"--------------------------extracting the verteces of each image in the dataset seperatly---------------------------------------\")\n",
    "    for i in range(54):\n",
    "        print(\"extracting the features grapph for image number:\", i,\" in the dataset\")\n",
    "        readed_image=imread(images[i])\n",
    "        features_matrix=np.zeros((readed_image.shape[0],readed_image.shape[1]))\n",
    "        \n",
    "        for i in range(0,readed_image.shape[0]):\n",
    "            for j in range(0,readed_image.shape[1]):\n",
    "                features_matrix[i][j] = ((int(readed_image[i,j,0]) + int(readed_image[i,j,1]) + int(readed_image[i,j,2]))/3)\n",
    "        resized_image=resize(features_matrix,(30,30))\n",
    "\n",
    "        garaph_of_the_current_image=[]\n",
    "        for i in range(0,resized_image.shape[0]):\n",
    "            for j in range(0,resized_image.shape[1]):\n",
    "                if(resized_image[i][j]<=150):\n",
    "                    garaph_of_the_current_image.append((i,j))\n",
    "        #adding the graph of the curent image in the list \n",
    "        list_of_images_graphs.append(garaph_of_the_current_image)    \n",
    "    return list_of_images_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87205ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_extract_the_black_pixels_of_check_image():\n",
    "    readed_image=imread(\"checkImage.png\",as_gray=False)\n",
    "    features_matrix=np.zeros((readed_image.shape[0],readed_image.shape[1]))\n",
    "\n",
    "    for i in range(0,readed_image.shape[0]):\n",
    "        for j in range(0,readed_image.shape[1]):\n",
    "            features_matrix[i][j] = ((int(readed_image[i,j,0]) + int(readed_image[i,j,1]) + int(readed_image[i,j,2]))/3)\n",
    "    resized_image=resize(features_matrix,(30,30))\n",
    "    \n",
    "    garaph_of_the_current_image=[]\n",
    "    for i in range(0,resized_image.shape[0]):\n",
    "        for j in range(0,resized_image.shape[1]):\n",
    "            if(resized_image[i][j]<=150):\n",
    "                garaph_of_the_current_image.append((i,j))\n",
    "    return garaph_of_the_current_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b0a07",
   "metadata": {},
   "source": [
    "# Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f968d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(pic1,pic2):\n",
    "    resultt=[]\n",
    "    small_list=len(pic1)<len(pic2) and pic1 or pic2\n",
    "    big_list=len(pic1)>len(pic2) and pic1 or pic2\n",
    "    for i in range(0, len(small_list)):\n",
    "        resultt.append((abs(pic1[i][0]-pic2[i][0]),abs(pic1[i][1]-pic2[i][1])))\n",
    "    temp=big_list[len(small_list):]\n",
    "    resultt.extend(temp)\n",
    "    sum=0\n",
    "    for i in range(0, len(resultt)):\n",
    "        sum+=resultt[i][0]+resultt[i][0]\n",
    "    return(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b0c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clculate_fitness_of_checkImageAndTheinitialPopulation(initialPopulation,checkImage):\n",
    "    resul=[]\n",
    "    for i in range(len(initialPopulation)):\n",
    "        temp=initialPopulation[i]\n",
    "        resul.append(fitness(temp[:],checkImage))\n",
    "    return(resul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15c35e",
   "metadata": {},
   "source": [
    "# Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "298c41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TheNFitestIndexOfCromosomes(fitnessArray,numberOfTheNeededCromosomes):\n",
    "    temp=fitnessArray[:]\n",
    "    fitestN=[]\n",
    "    fitestIndexs=[]\n",
    "    n=0\n",
    "    for i in range(numberOfTheNeededCromosomes):\n",
    "        a=min(temp)\n",
    "        fitestN.append(a)\n",
    "        temp.pop(indexOf(temp,a))\n",
    "    for i in range(numberOfTheNeededCromosomes):\n",
    "        index=indexOf(fitnessArray,fitestN[i])\n",
    "        fitestIndexs.append(index)\n",
    "    return(fitestIndexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b00c23aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTheIndexToCromosom(arrayOfIndexes,initialPopulation):\n",
    "    ar=[]\n",
    "    for i in range(len(arrayOfIndexes)):\n",
    "        ar.append(initialPopulation[arrayOfIndexes[i]])\n",
    "    return(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d103c9d",
   "metadata": {},
   "source": [
    "# Cross-Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86d5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossPoint(paran1,paran2):\n",
    "    small_list=len(paran1)<len(paran2) and paran1 or paran2\n",
    "    return(len(small_list)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "138bdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossoverForTwoLists(paran1,paran2):\n",
    "    crosPoint=crossPoint(paran1,paran2)\n",
    "    tempx=paran1[:]\n",
    "    temp=paran1[0:crosPoint]\n",
    "    temp1=paran2[crosPoint:]\n",
    "    temp.extend(temp1)\n",
    "    arr=temp[:]\n",
    "    temp=[]\n",
    "    temp1=[]\n",
    "    temp=paran2[0:crosPoint]\n",
    "    temp1=tempx[crosPoint:]\n",
    "    temp.extend(temp1)\n",
    "    paran2=temp[:]\n",
    "    return(paran1,paran2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2116937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossOver(listOfNFitestIndex,initialPopulation):\n",
    "    listOfTheFitestChromosomes=convertTheIndexToCromosom(listOfNFitestIndex,initialPopulation)\n",
    "    listOfOfsprings=[]\n",
    "    for i in range(3):\n",
    "        ofs1,ofs2=crossoverForTwoLists(listOfTheFitestChromosomes[i],listOfTheFitestChromosomes[i+1])\n",
    "        listOfOfsprings.append(ofs1)\n",
    "        listOfOfsprings.append(ofs2)\n",
    "    listOfTheFitestChromosomes.extend(listOfOfsprings)\n",
    "    return(listOfTheFitestChromosomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb31ac0d",
   "metadata": {},
   "source": [
    "# Starting Point :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fb32a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************** the start of excution ***************************************\n",
      "checkImage.png\n",
      "-------------------------Column headings----------------------------------------\n",
      "['image path', 'character']\n",
      "-----------------------------------------------------------------\n",
      "--------------------------extracting the verteces of each image in the dataset seperatly---------------------------------------\n",
      "extracting the features grapph for image number: 0  in the dataset\n",
      "extracting the features grapph for image number: 1  in the dataset\n",
      "extracting the features grapph for image number: 2  in the dataset\n",
      "extracting the features grapph for image number: 3  in the dataset\n",
      "extracting the features grapph for image number: 4  in the dataset\n",
      "extracting the features grapph for image number: 5  in the dataset\n",
      "extracting the features grapph for image number: 6  in the dataset\n",
      "extracting the features grapph for image number: 7  in the dataset\n",
      "extracting the features grapph for image number: 8  in the dataset\n",
      "extracting the features grapph for image number: 9  in the dataset\n",
      "extracting the features grapph for image number: 10  in the dataset\n",
      "extracting the features grapph for image number: 11  in the dataset\n",
      "extracting the features grapph for image number: 12  in the dataset\n",
      "extracting the features grapph for image number: 13  in the dataset\n",
      "extracting the features grapph for image number: 14  in the dataset\n",
      "extracting the features grapph for image number: 15  in the dataset\n",
      "extracting the features grapph for image number: 16  in the dataset\n",
      "extracting the features grapph for image number: 17  in the dataset\n",
      "extracting the features grapph for image number: 18  in the dataset\n",
      "extracting the features grapph for image number: 19  in the dataset\n",
      "extracting the features grapph for image number: 20  in the dataset\n",
      "extracting the features grapph for image number: 21  in the dataset\n",
      "extracting the features grapph for image number: 22  in the dataset\n",
      "extracting the features grapph for image number: 23  in the dataset\n",
      "extracting the features grapph for image number: 24  in the dataset\n",
      "extracting the features grapph for image number: 25  in the dataset\n",
      "extracting the features grapph for image number: 26  in the dataset\n",
      "extracting the features grapph for image number: 27  in the dataset\n",
      "extracting the features grapph for image number: 28  in the dataset\n",
      "extracting the features grapph for image number: 29  in the dataset\n",
      "extracting the features grapph for image number: 30  in the dataset\n",
      "extracting the features grapph for image number: 31  in the dataset\n",
      "extracting the features grapph for image number: 32  in the dataset\n",
      "extracting the features grapph for image number: 33  in the dataset\n",
      "extracting the features grapph for image number: 34  in the dataset\n",
      "extracting the features grapph for image number: 35  in the dataset\n",
      "extracting the features grapph for image number: 36  in the dataset\n",
      "extracting the features grapph for image number: 37  in the dataset\n",
      "extracting the features grapph for image number: 38  in the dataset\n",
      "extracting the features grapph for image number: 39  in the dataset\n",
      "extracting the features grapph for image number: 40  in the dataset\n",
      "extracting the features grapph for image number: 41  in the dataset\n",
      "extracting the features grapph for image number: 42  in the dataset\n",
      "extracting the features grapph for image number: 43  in the dataset\n",
      "extracting the features grapph for image number: 44  in the dataset\n",
      "extracting the features grapph for image number: 45  in the dataset\n",
      "extracting the features grapph for image number: 46  in the dataset\n",
      "extracting the features grapph for image number: 47  in the dataset\n",
      "extracting the features grapph for image number: 48  in the dataset\n",
      "extracting the features grapph for image number: 49  in the dataset\n",
      "extracting the features grapph for image number: 50  in the dataset\n",
      "extracting the features grapph for image number: 51  in the dataset\n",
      "extracting the features grapph for image number: 52  in the dataset\n",
      "extracting the features grapph for image number: 53  in the dataset\n",
      "****************************************************************************************************\n",
      "********************************* the check image features vector **********************************\n",
      "****************************************************************************************************\n",
      "*********************************** the fitness values for a are ***********************************\n",
      "****************************************************************************************************\n",
      "the fitness was :\n",
      " [4806, 5000, 5006, 5142, 5250]\n",
      "****************************************************************************************************\n",
      "the fitness is now:\n",
      " [4806, 5000, 5006, 5142, 5250, 4806, 4784, 5000, 5088, 5006, 4890]\n",
      "************************************ the fitness of being A is *************************************\n",
      "0.00020903010033444816\n",
      "-------------------------Column headings----------------------------------------\n",
      "['image path', 'character']\n",
      "-----------------------------------------------------------------\n",
      "--------------------------extracting the verteces of each image in the dataset seperatly---------------------------------------\n",
      "extracting the features grapph for image number: 0  in the dataset\n",
      "extracting the features grapph for image number: 1  in the dataset\n",
      "extracting the features grapph for image number: 2  in the dataset\n",
      "extracting the features grapph for image number: 3  in the dataset\n",
      "extracting the features grapph for image number: 4  in the dataset\n",
      "extracting the features grapph for image number: 5  in the dataset\n",
      "extracting the features grapph for image number: 6  in the dataset\n",
      "extracting the features grapph for image number: 7  in the dataset\n",
      "extracting the features grapph for image number: 8  in the dataset\n",
      "extracting the features grapph for image number: 9  in the dataset\n",
      "extracting the features grapph for image number: 10  in the dataset\n",
      "extracting the features grapph for image number: 11  in the dataset\n",
      "extracting the features grapph for image number: 12  in the dataset\n",
      "extracting the features grapph for image number: 13  in the dataset\n",
      "extracting the features grapph for image number: 14  in the dataset\n",
      "extracting the features grapph for image number: 15  in the dataset\n",
      "extracting the features grapph for image number: 16  in the dataset\n",
      "extracting the features grapph for image number: 17  in the dataset\n",
      "extracting the features grapph for image number: 18  in the dataset\n",
      "extracting the features grapph for image number: 19  in the dataset\n",
      "extracting the features grapph for image number: 20  in the dataset\n",
      "extracting the features grapph for image number: 21  in the dataset\n",
      "extracting the features grapph for image number: 22  in the dataset\n",
      "extracting the features grapph for image number: 23  in the dataset\n",
      "extracting the features grapph for image number: 24  in the dataset\n",
      "extracting the features grapph for image number: 25  in the dataset\n",
      "extracting the features grapph for image number: 26  in the dataset\n",
      "extracting the features grapph for image number: 27  in the dataset\n",
      "extracting the features grapph for image number: 28  in the dataset\n",
      "extracting the features grapph for image number: 29  in the dataset\n",
      "extracting the features grapph for image number: 30  in the dataset\n",
      "extracting the features grapph for image number: 31  in the dataset\n",
      "extracting the features grapph for image number: 32  in the dataset\n",
      "extracting the features grapph for image number: 33  in the dataset\n",
      "extracting the features grapph for image number: 34  in the dataset\n",
      "extracting the features grapph for image number: 35  in the dataset\n",
      "extracting the features grapph for image number: 36  in the dataset\n",
      "extracting the features grapph for image number: 37  in the dataset\n",
      "extracting the features grapph for image number: 38  in the dataset\n",
      "extracting the features grapph for image number: 39  in the dataset\n",
      "extracting the features grapph for image number: 40  in the dataset\n",
      "extracting the features grapph for image number: 41  in the dataset\n",
      "extracting the features grapph for image number: 42  in the dataset\n",
      "extracting the features grapph for image number: 43  in the dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting the features grapph for image number: 44  in the dataset\n",
      "extracting the features grapph for image number: 45  in the dataset\n",
      "extracting the features grapph for image number: 46  in the dataset\n",
      "extracting the features grapph for image number: 47  in the dataset\n",
      "extracting the features grapph for image number: 48  in the dataset\n",
      "extracting the features grapph for image number: 49  in the dataset\n",
      "extracting the features grapph for image number: 50  in the dataset\n",
      "extracting the features grapph for image number: 51  in the dataset\n",
      "extracting the features grapph for image number: 52  in the dataset\n",
      "extracting the features grapph for image number: 53  in the dataset\n",
      "****************************************************************************************************\n",
      "*********************************** the fitness values for J are ***********************************\n",
      "****************************************************************************************************\n",
      "the fitness for J was :\n",
      " [4536, 4800, 4910, 4958, 4998]\n",
      "****************************************************************************************************\n",
      "the fitness for J is now:\n",
      " [4536, 4800, 4910, 4958, 4998, 4536, 4552, 4800, 4754, 4910, 4934]\n",
      "************************************ the fitness of being J is *************************************\n",
      "0.0002204585537918871\n",
      "the handwrtten letter was :- j\n"
     ]
    }
   ],
   "source": [
    "print(\" the start of excution \".center(100,'*'))\n",
    "fuction_to_capture_and_store_the_check_image()\n",
    "initialPopulationForA= function_to_extract_the_features_of_the_initial_population_For_a_dataset()\n",
    "print(\"*\"*100)\n",
    "print(\" the check image features vector \".center(100,'*'))\n",
    "print(\"*\"*100)\n",
    "checkImage=function_to_extract_the_black_pixels_of_check_image()\n",
    "print(\" the fitness values for a are \".center(100,'*'))\n",
    "fitListForA=clculate_fitness_of_checkImageAndTheinitialPopulation(initialPopulationForA,checkImage)\n",
    "theFitestIthsForA=TheNFitestIndexOfCromosomes(fitListForA,5)\n",
    "wasBEFORETHECROSSOVERForA=convertTheIndexToCromosom(theFitestIthsForA,fitListForA)\n",
    "print(\"*\"*100)\n",
    "print(\"the fitness was :\\n\",wasBEFORETHECROSSOVERForA)\n",
    "print(\"*\"*100)\n",
    "listOfNewPopulationForA=crossOver(theFitestIthsForA,initialPopulationForA)\n",
    "newFitListForA=clculate_fitness_of_checkImageAndTheinitialPopulation(listOfNewPopulationForA,checkImage)\n",
    "print(\"the fitness is now:\\n\",newFitListForA)\n",
    "print(\" the fitness of being A is \".center(100,'*'))\n",
    "probabilityOfBiengA=1/min(newFitListForA)\n",
    "print(probabilityOfBiengA)\n",
    "\n",
    "\n",
    "initialPopulationForJDataSet= function_to_extract_the_features_of_the_initial_population_for_J_dataset()\n",
    "print(\"*\"*100)\n",
    "print(\" the fitness values for J are \".center(100,'*'))\n",
    "fitListForJ=clculate_fitness_of_checkImageAndTheinitialPopulation(initialPopulationForJDataSet,checkImage)\n",
    "theFitestIthsForJ=TheNFitestIndexOfCromosomes(fitListForJ,5)\n",
    "wasBEFORETHECROSSOVErForJ=convertTheIndexToCromosom(theFitestIthsForJ,fitListForJ)\n",
    "print(\"*\"*100)\n",
    "print(\"the fitness for J was :\\n\",wasBEFORETHECROSSOVErForJ)\n",
    "print(\"*\"*100)\n",
    "listOfNewPopulationForj=crossOver(theFitestIthsForJ,initialPopulationForJDataSet)\n",
    "newFitListForJ=clculate_fitness_of_checkImageAndTheinitialPopulation(listOfNewPopulationForj,checkImage)\n",
    "print(\"the fitness for J is now:\\n\",newFitListForJ)\n",
    "print(\" the fitness of being J is \".center(100,'*'))\n",
    "probabilityOfBiengj=1/min(newFitListForJ)\n",
    "print(probabilityOfBiengj)\n",
    "\n",
    "if (probabilityOfBiengA>probabilityOfBiengj):\n",
    "    print(\"the handwrtten letter was :- A\")\n",
    "else:\n",
    "    print(\"the handwrtten letter was :- j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff6f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
